{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"modelling.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOjBBLzIN/iNrutad9kT4JL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-VsREPJdlJCw","executionInfo":{"status":"ok","timestamp":1654425902531,"user_tz":-180,"elapsed":10437,"user":{"displayName":"Selam Ayehubirhan","userId":"06798422864346636867"}},"outputId":"d7e07145-ccac-4ebc-e8ff-5c0c6644101d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: jiwer in /usr/local/lib/python3.7/dist-packages (2.3.0)\n","Requirement already satisfied: python-Levenshtein==0.12.2 in /usr/local/lib/python3.7/dist-packages (from jiwer) (0.12.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from python-Levenshtein==0.12.2->jiwer) (57.4.0)\n"]}],"source":["!pip install jiwer\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","import matplotlib.pyplot as plt\n","from IPython import display\n","from jiwer import wer\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import FunctionTransformer"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JONPcY77lSCT","executionInfo":{"status":"ok","timestamp":1654417579744,"user_tz":-180,"elapsed":2258,"user":{"displayName":"Selam Ayehubirhan","userId":"06798422864346636867"}},"outputId":"ddbeb35f-f858-46af-f3eb-3bcda02b8a32"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import os\n","os.chdir(\"drive/MyDrive/AMHARIC\")\n","os.listdir()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"72zyhw88lTWg","executionInfo":{"status":"ok","timestamp":1654425905115,"user_tz":-180,"elapsed":18,"user":{"displayName":"Selam Ayehubirhan","userId":"06798422864346636867"}},"outputId":"2c1a6b21-39cc-486e-db34-dd8c3de89e9f"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['README.md',\n"," 'data',\n"," 'kaldi-script',\n"," 'lang',\n"," 'lm',\n"," 'metadata.csv',\n"," 'realmeta.csv',\n"," '.git']"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["meta_data = pd.read_csv(\"realmeta.csv\")\n","meta_data. drop(\"Unnamed: 0\", axis=1, inplace=True)\n","meta_data = meta_data.sample(n=100)"],"metadata":{"id":"1MAF05gplUBw","executionInfo":{"status":"ok","timestamp":1654425905117,"user_tz":-180,"elapsed":15,"user":{"displayName":"Selam Ayehubirhan","userId":"06798422864346636867"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["split = int(len(meta_data) * 0.90)\n","df_train = meta_data[:split]\n","df_val = meta_data[split:]\n","\n","print(f\"Size of the training set: {len(df_train)}\")\n","print(f\"Size of the training set: {len(df_val)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LrIUXFbClUeo","executionInfo":{"status":"ok","timestamp":1654425905118,"user_tz":-180,"elapsed":15,"user":{"displayName":"Selam Ayehubirhan","userId":"06798422864346636867"}},"outputId":"853ebad2-67e8-4e4a-9754-13c3d251fd06"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Size of the training set: 90\n","Size of the training set: 10\n"]}]},{"cell_type":"code","source":["supported = \"\"\"\n","ሀ ሁ ሂ ሄ ህ ሆ\n","ለ ሉ ሊ ላ ሌ ል ሎ ሏ\n","መ ሙ ሚ ማ ሜ ም ሞ ሟ\n","ረ ሩ ሪ ራ ሬ ር ሮ ሯ\n","ሰ ሱ ሲ ሳ ሴ ስ ሶ ሷ\n","ሸ ሹ ሺ ሻ ሼ ሽ ሾ ሿ\n","ቀ ቁ ቂ ቃ ቄ ቅ ቆ ቋ\n","በ ቡ ቢ ባ ቤ ብ ቦ ቧ\n","ቨ ቩ ቪ ቫ ቬ ቭ ቮ ቯ\n","ተ ቱ ቲ ታ ቴ ት ቶ ቷ\n","ቸ ቹ ቺ ቻ ቼ ች ቾ ቿ\n","ኋ\n","ነ ኑ ኒ ና ኔ ን ኖ ኗ\n","ኘ ኙ ኚ ኛ ኜ ኝ ኞ ኟ\n","አ ኡ ኢ ኤ እ ኦ\n","ኧ\n","ከ ኩ ኪ ካ ኬ ክ ኮ\n","ኳ\n","ወ ዉ ዊ ዋ ዌ ው ዎ\n","ዘ ዙ ዚ ዛ ዜ ዝ ዞ ዟ\n","ዠ ዡ ዢ ዣ ዤ ዥ ዦ ዧ\n","የ ዩ ዪ ያ ዬ ይ ዮ\n","ደ ዱ ዲ ዳ ዴ ድ ዶ ዷ\n","ጀ ጁ ጂ ጃ ጄ ጅ ጆ ጇ\n","ገ ጉ ጊ ጋ ጌ ግ ጐ ጓ ጔ\n","ጠ ጡ ጢ ጣ ጤ ጥ ጦ ጧ\n","ጨ ጩ ጪ ጫ ጬ ጭ ጮ ጯ\n","ጰ ጱ ጲ ጳ ጴ ጵ ጶ ጷ\n","ፀ ፁ ፂ ፃ ፄ ፅ ፆ ፇ\n","ፈ ፉ ፊ ፋ ፌ ፍ ፎ ፏ\n","ፐ ፑ ፒ ፓ ፔ ፕ ፖ\n","\"\"\".split()\n","\n","char_map = {}\n","char_map[\"\"] = 0\n","char_map[\" \"] = 1\n","index = 2\n","for c in supported:\n","    char_map[c] = index\n","    index += 1\n","index_map = {v+1: k for k, v in char_map.items()}\n","lan_lis = list(index_map.values())\n","print(lan_lis)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aaSJKq1wqCNf","executionInfo":{"status":"ok","timestamp":1654425905119,"user_tz":-180,"elapsed":10,"user":{"displayName":"Selam Ayehubirhan","userId":"06798422864346636867"}},"outputId":"27634d4e-a115-46fc-865d-49e27ab0d8b8"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["['', ' ', 'ሀ', 'ሁ', 'ሂ', 'ሄ', 'ህ', 'ሆ', 'ለ', 'ሉ', 'ሊ', 'ላ', 'ሌ', 'ል', 'ሎ', 'ሏ', 'መ', 'ሙ', 'ሚ', 'ማ', 'ሜ', 'ም', 'ሞ', 'ሟ', 'ረ', 'ሩ', 'ሪ', 'ራ', 'ሬ', 'ር', 'ሮ', 'ሯ', 'ሰ', 'ሱ', 'ሲ', 'ሳ', 'ሴ', 'ስ', 'ሶ', 'ሷ', 'ሸ', 'ሹ', 'ሺ', 'ሻ', 'ሼ', 'ሽ', 'ሾ', 'ሿ', 'ቀ', 'ቁ', 'ቂ', 'ቃ', 'ቄ', 'ቅ', 'ቆ', 'ቋ', 'በ', 'ቡ', 'ቢ', 'ባ', 'ቤ', 'ብ', 'ቦ', 'ቧ', 'ቨ', 'ቩ', 'ቪ', 'ቫ', 'ቬ', 'ቭ', 'ቮ', 'ቯ', 'ተ', 'ቱ', 'ቲ', 'ታ', 'ቴ', 'ት', 'ቶ', 'ቷ', 'ቸ', 'ቹ', 'ቺ', 'ቻ', 'ቼ', 'ች', 'ቾ', 'ቿ', 'ኋ', 'ነ', 'ኑ', 'ኒ', 'ና', 'ኔ', 'ን', 'ኖ', 'ኗ', 'ኘ', 'ኙ', 'ኚ', 'ኛ', 'ኜ', 'ኝ', 'ኞ', 'ኟ', 'አ', 'ኡ', 'ኢ', 'ኤ', 'እ', 'ኦ', 'ኧ', 'ከ', 'ኩ', 'ኪ', 'ካ', 'ኬ', 'ክ', 'ኮ', 'ኳ', 'ወ', 'ዉ', 'ዊ', 'ዋ', 'ዌ', 'ው', 'ዎ', 'ዘ', 'ዙ', 'ዚ', 'ዛ', 'ዜ', 'ዝ', 'ዞ', 'ዟ', 'ዠ', 'ዡ', 'ዢ', 'ዣ', 'ዤ', 'ዥ', 'ዦ', 'ዧ', 'የ', 'ዩ', 'ዪ', 'ያ', 'ዬ', 'ይ', 'ዮ', 'ደ', 'ዱ', 'ዲ', 'ዳ', 'ዴ', 'ድ', 'ዶ', 'ዷ', 'ጀ', 'ጁ', 'ጂ', 'ጃ', 'ጄ', 'ጅ', 'ጆ', 'ጇ', 'ገ', 'ጉ', 'ጊ', 'ጋ', 'ጌ', 'ግ', 'ጐ', 'ጓ', 'ጔ', 'ጠ', 'ጡ', 'ጢ', 'ጣ', 'ጤ', 'ጥ', 'ጦ', 'ጧ', 'ጨ', 'ጩ', 'ጪ', 'ጫ', 'ጬ', 'ጭ', 'ጮ', 'ጯ', 'ጰ', 'ጱ', 'ጲ', 'ጳ', 'ጴ', 'ጵ', 'ጶ', 'ጷ', 'ፀ', 'ፁ', 'ፂ', 'ፃ', 'ፄ', 'ፅ', 'ፆ', 'ፇ', 'ፈ', 'ፉ', 'ፊ', 'ፋ', 'ፌ', 'ፍ', 'ፎ', 'ፏ', 'ፐ', 'ፑ', 'ፒ', 'ፓ', 'ፔ', 'ፕ', 'ፖ']\n"]}]},{"cell_type":"code","source":["wavs_path_train = (\"data/train/wav/\")\n","wavs_path_test = (\"data/test/wav/\")"],"metadata":{"id":"qlESw6l8rjLW","executionInfo":{"status":"ok","timestamp":1654425908795,"user_tz":-180,"elapsed":412,"user":{"displayName":"Selam Ayehubirhan","userId":"06798422864346636867"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# Mapping characters to integers\n","char_to_num = keras.layers.StringLookup(vocabulary=lan_lis, oov_token=\"\")\n","# Mapping integers back to original characters\n","num_to_char = keras.layers.StringLookup(\n","    vocabulary=char_to_num.get_vocabulary(), oov_token=\"\", invert=True\n",")"],"metadata":{"id":"ogzcIuDtlUub","executionInfo":{"status":"ok","timestamp":1654425909279,"user_tz":-180,"elapsed":4,"user":{"displayName":"Selam Ayehubirhan","userId":"06798422864346636867"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# An integer scalar Tensor. The window length in samples.\n","frame_length = 256\n","# An integer scalar Tensor. The number of samples to step.\n","frame_step = 160\n","# An integer scalar Tensor. The size of the FFT to apply.\n","# If not provided, uses the smallest power of 2 enclosing frame_length.\n","fft_length = 384\n","\n","\n","def encode_single_sample(wav_file, label):\n","    ###########################################\n","    ##  Process the Audio\n","    ##########################################\n","    # 1. Read wav file\n","    file = tf.io.read_file(wavs_path_train + wav_file)\n","    # 2. Decode the wav file\n","    audio, _ = tf.audio.decode_wav(file)\n","    audio = tf.squeeze(audio, axis=-1)\n","    # 3. Change type to float\n","    audio = tf.cast(audio, tf.float32)\n","    # 4. Get the spectrogram\n","    spectrogram = tf.signal.stft(\n","        audio, frame_length=frame_length, frame_step=frame_step, fft_length=fft_length\n","    )\n","    # 5. We only need the magnitude, which can be derived by applying tf.abs\n","    spectrogram = tf.abs(spectrogram)\n","    spectrogram = tf.math.pow(spectrogram, 0.5)\n","    # 6. normalisation\n","    means = tf.math.reduce_mean(spectrogram, 1, keepdims=True)\n","    stddevs = tf.math.reduce_std(spectrogram, 1, keepdims=True)\n","    spectrogram = (spectrogram - means) / (stddevs + 1e-10)\n","    ###########################################\n","    ##  Process the label\n","    ##########################################\n","    # 7. Convert label to Lower case\n","    label = tf.strings.lower(label)\n","    # 8. Split the label\n","    label = tf.strings.unicode_split(label, input_encoding=\"UTF-8\")\n","    # 9. Map the characters in label to numbers\n","    label = char_to_num(label)\n","    # 10. Return a dict as our model is expecting two inputs\n","    return spectrogram, label"],"metadata":{"id":"Nih9uRsnlVZw","executionInfo":{"status":"ok","timestamp":1654425912032,"user_tz":-180,"elapsed":528,"user":{"displayName":"Selam Ayehubirhan","userId":"06798422864346636867"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["batch_size = 32\n","# Define the trainig dataset\n","train_dataset = tf.data.Dataset.from_tensor_slices(\n","    (list(df_train[\"audio\"]), list(df_train[\"Transcript\"]))\n",")\n","train_dataset = (\n","    train_dataset.map(encode_single_sample, num_parallel_calls=tf.data.AUTOTUNE)\n","    .padded_batch(batch_size)\n","    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",")\n","\n","# Define the validation dataset\n","validation_dataset = tf.data.Dataset.from_tensor_slices(\n","    (list(df_val[\"audio\"]), list(df_val[\"Transcript\"]))\n",")\n","validation_dataset = (\n","    validation_dataset.map(encode_single_sample, num_parallel_calls=tf.data.AUTOTUNE)\n","    .padded_batch(batch_size)\n","    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",")"],"metadata":{"id":"SDudniwkqnmY","executionInfo":{"status":"ok","timestamp":1654425919224,"user_tz":-180,"elapsed":983,"user":{"displayName":"Selam Ayehubirhan","userId":"06798422864346636867"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def CTCLoss(y_true, y_pred):\n","    # Compute the training-time loss value\n","    batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n","    input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n","    label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n","\n","    input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n","    label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n","\n","    loss = keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n","    return loss"],"metadata":{"id":"1jPV4KQ2qpeG","executionInfo":{"status":"ok","timestamp":1654425921709,"user_tz":-180,"elapsed":362,"user":{"displayName":"Selam Ayehubirhan","userId":"06798422864346636867"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["## Model"],"metadata":{"id":"V397rTIncN7T"}},{"cell_type":"code","source":["def build_model(input_dim, output_dim, rnn_layers=5, rnn_units=128):\n","    \"\"\"Model similar to DeepSpeech2.\"\"\"\n","    # Model's input\n","    input_spectrogram = layers.Input((None, input_dim), name=\"input\")\n","    # Expand the dimension to use 2D CNN.\n","    x = layers.Reshape((-1, input_dim, 1), name=\"expand_dim\")(input_spectrogram)\n","    # Convolution layer 1\n","    x = layers.Conv2D(\n","        filters=32,\n","        kernel_size=[11, 41],\n","        strides=[2, 2],\n","        padding=\"same\",\n","        use_bias=False,\n","        name=\"conv_1\",\n","    )(x)\n","    x = layers.BatchNormalization(name=\"conv_1_bn\")(x)\n","    x = layers.ReLU(name=\"conv_1_relu\")(x)\n","    # Convolution layer 2\n","    x = layers.Conv2D(\n","        filters=32,\n","        kernel_size=[11, 21],\n","        strides=[1, 2],\n","        padding=\"same\",\n","        use_bias=False,\n","        name=\"conv_2\",\n","    )(x)\n","    x = layers.BatchNormalization(name=\"conv_2_bn\")(x)\n","    x = layers.ReLU(name=\"conv_2_relu\")(x)\n","    # Reshape the resulted volume to feed the RNNs layers\n","    x = layers.Reshape((-1, x.shape[-2] * x.shape[-1]))(x)\n","    # RNN layers\n","    for i in range(1, rnn_layers + 1):\n","        recurrent = layers.GRU(\n","            units=rnn_units,\n","            activation=\"tanh\",\n","            recurrent_activation=\"sigmoid\",\n","            use_bias=True,\n","            return_sequences=True,\n","            reset_after=True,\n","            name=f\"gru_{i}\",\n","        )\n","        x = layers.Bidirectional(\n","            recurrent, name=f\"bidirectional_{i}\", merge_mode=\"concat\"\n","        )(x)\n","        if i < rnn_layers:\n","            x = layers.Dropout(rate=0.5)(x)\n","    # Dense layer\n","    x = layers.Dense(units=rnn_units * 2, name=\"dense_1\")(x)\n","    x = layers.ReLU(name=\"dense_1_relu\")(x)\n","    x = layers.Dropout(rate=0.5)(x)\n","    # Classification layer\n","    output = layers.Dense(units=output_dim + 1, activation=\"softmax\")(x)\n","    # Model\n","    model = keras.Model(input_spectrogram, output, name=\"DeepSpeech_2\")\n","    # Optimizer\n","    opt = keras.optimizers.Adam(learning_rate=1e-4)\n","    # Compile the model and return\n","    model.compile(optimizer=opt, loss=CTCLoss)\n","    return model\n","\n","\n","# Get the model\n","model = build_model(\n","    input_dim=fft_length // 2 + 1,\n","    output_dim=char_to_num.vocabulary_size(),\n","    rnn_units=512,\n",")\n","model.summary(line_length=110)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lNh8FdmEqp5l","executionInfo":{"status":"ok","timestamp":1654425928086,"user_tz":-180,"elapsed":5114,"user":{"displayName":"Selam Ayehubirhan","userId":"06798422864346636867"}},"outputId":"9044641e-5d11-4df4-cba0-02afde02067e"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"DeepSpeech_2\"\n","______________________________________________________________________________________________________________\n"," Layer (type)                                    Output Shape                                Param #          \n","==============================================================================================================\n"," input (InputLayer)                              [(None, None, 193)]                         0                \n","                                                                                                              \n"," expand_dim (Reshape)                            (None, None, 193, 1)                        0                \n","                                                                                                              \n"," conv_1 (Conv2D)                                 (None, None, 97, 32)                        14432            \n","                                                                                                              \n"," conv_1_bn (BatchNormalization)                  (None, None, 97, 32)                        128              \n","                                                                                                              \n"," conv_1_relu (ReLU)                              (None, None, 97, 32)                        0                \n","                                                                                                              \n"," conv_2 (Conv2D)                                 (None, None, 49, 32)                        236544           \n","                                                                                                              \n"," conv_2_bn (BatchNormalization)                  (None, None, 49, 32)                        128              \n","                                                                                                              \n"," conv_2_relu (ReLU)                              (None, None, 49, 32)                        0                \n","                                                                                                              \n"," reshape (Reshape)                               (None, None, 1568)                          0                \n","                                                                                                              \n"," bidirectional_1 (Bidirectional)                 (None, None, 1024)                          6395904          \n","                                                                                                              \n"," dropout (Dropout)                               (None, None, 1024)                          0                \n","                                                                                                              \n"," bidirectional_2 (Bidirectional)                 (None, None, 1024)                          4724736          \n","                                                                                                              \n"," dropout_1 (Dropout)                             (None, None, 1024)                          0                \n","                                                                                                              \n"," bidirectional_3 (Bidirectional)                 (None, None, 1024)                          4724736          \n","                                                                                                              \n"," dropout_2 (Dropout)                             (None, None, 1024)                          0                \n","                                                                                                              \n"," bidirectional_4 (Bidirectional)                 (None, None, 1024)                          4724736          \n","                                                                                                              \n"," dropout_3 (Dropout)                             (None, None, 1024)                          0                \n","                                                                                                              \n"," bidirectional_5 (Bidirectional)                 (None, None, 1024)                          4724736          \n","                                                                                                              \n"," dense_1 (Dense)                                 (None, None, 1024)                          1049600          \n","                                                                                                              \n"," dense_1_relu (ReLU)                             (None, None, 1024)                          0                \n","                                                                                                              \n"," dropout_4 (Dropout)                             (None, None, 1024)                          0                \n","                                                                                                              \n"," dense (Dense)                                   (None, None, 223)                           228575           \n","                                                                                                              \n","==============================================================================================================\n","Total params: 26,824,255\n","Trainable params: 26,824,127\n","Non-trainable params: 128\n","______________________________________________________________________________________________________________\n"]}]},{"cell_type":"code","source":["# A utility function to decode the output of the network\n","def decode_batch_predictions(pred):\n","    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n","    # Use greedy search. For complex tasks, you can use beam search\n","    results = keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0]\n","    # Iterate over the results and get back the text\n","    output_text = []\n","    for result in results:\n","        result = tf.strings.reduce_join(num_to_char(result)).numpy().decode(\"utf-8\")\n","        output_text.append(result)\n","    return output_text\n","\n","\n","# A callback class to output a few transcriptions during training\n","class CallbackEval(keras.callbacks.Callback):\n","    \"\"\"Displays a batch of outputs after every epoch.\"\"\"\n","\n","    def __init__(self, dataset):\n","        super().__init__()\n","        self.dataset = dataset\n","\n","    def on_epoch_end(self, epoch: int, logs=None):\n","        predictions = []\n","        targets = []\n","        for batch in self.dataset:\n","            X, y = batch\n","            batch_predictions = model.predict(X)\n","            batch_predictions = decode_batch_predictions(batch_predictions)\n","            predictions.extend(batch_predictions)\n","            for label in y:\n","                label = (\n","                    tf.strings.reduce_join(num_to_char(label)).numpy().decode(\"utf-8\")\n","                )\n","                targets.append(label)\n","        wer_score = wer(targets, predictions)\n","        print(\"-\" * 100)\n","        print(f\"Word Error Rate: {wer_score:.4f}\")\n","        print(\"-\" * 100)\n","        for i in np.random.randint(0, len(predictions), 2):\n","            print(f\"Target    : {targets[i]}\")\n","            print(f\"Prediction: {predictions[i]}\")\n","            print(\"-\" * 100)"],"metadata":{"id":"ioDNjjG2qqet","executionInfo":{"status":"ok","timestamp":1654425935450,"user_tz":-180,"elapsed":410,"user":{"displayName":"Selam Ayehubirhan","userId":"06798422864346636867"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["## Evaluation"],"metadata":{"id":"ORXAx0jpb-Y2"}},{"cell_type":"code","source":["# Let's check results on more validation samples\n","predictions = []\n","targets = []\n","for batch in validation_dataset:\n","    X, y = batch\n","    batch_predictions = model.predict(X)\n","    batch_predictions = decode_batch_predictions(batch_predictions)\n","    predictions.extend(batch_predictions)\n","    for label in y:\n","        label = tf.strings.reduce_join(num_to_char(label)).numpy().decode(\"utf-8\")\n","        targets.append(label)\n","wer_score = wer(targets, predictions)\n","print(\"-\" * 100)\n","print(f\"Word Error Rate: {wer_score:.4f}\")\n","print(\"-\" * 100)\n","for i in np.random.randint(0, len(predictions), 5):\n","    print(f\"Target    : {targets[i]}\")\n","    print(f\"Prediction: {predictions[i]}\")\n","    print(\"-\" * 100)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dHJ1qTbbUGna","executionInfo":{"status":"ok","timestamp":1654425451137,"user_tz":-180,"elapsed":82411,"user":{"displayName":"Selam Ayehubirhan","userId":"06798422864346636867"}},"outputId":"a9c3e09a-b330-4e34-bcec-7ac10d563bc5"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------------------------------------------\n","Word Error Rate: 1.0000\n","----------------------------------------------------------------------------------------------------\n","Target    : ኢትዮጵያ ኤርትራ የምት ባል አዲስ ጐረቤት ሀገር አላ ት\n","Prediction: \n","----------------------------------------------------------------------------------------------------\n","Target    : ቀደም ሲል የ ፈማቸው ን ስህተቶች እንዳይ ደግም ና እርም ት እንዲያደርግ የሚ ገስው ሀይል ካልተገኘ ወደፊት ም በ ማወቅ ወይም ባለ ማወቅ ከ ስህተት የ ዳ ሊሆን አይችልም\n","Prediction: \n","----------------------------------------------------------------------------------------------------\n","Target    : ወደ ሱዳን ከ ሸሹ ት ኤርትራውያን ውስጥ አምስት ሺ ያህሉ ወታደሮች መሆናቸው ተረጋገጠ\n","Prediction: \n","----------------------------------------------------------------------------------------------------\n","Target    : ክሱ ም ን እንደሆነ ም አያውቁ\n","Prediction: \n","----------------------------------------------------------------------------------------------------\n","Target    : በሽታ ዎቹን ሆነ ብለው ነው ባ ፍሪካ ምድር ሁሉ ያሰራጯቸው ይባላል\n","Prediction: \n","----------------------------------------------------------------------------------------------------\n"]}]},{"cell_type":"code","source":["# Define the number of epochs.\n","epochs = 5\n","# Callback function to check transcription on the val set.\n","validation_callback = CallbackEval(validation_dataset)\n","# Train the model\n","history = model.fit(\n","    train_dataset,\n","    validation_data=validation_dataset,\n","    epochs=epochs,\n","    callbacks=[validation_callback],\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y0BRqalkflk5","executionInfo":{"status":"ok","timestamp":1654435923074,"user_tz":-180,"elapsed":5173538,"user":{"displayName":"Selam Ayehubirhan","userId":"06798422864346636867"}},"outputId":"a47ac0e5-88db-4b06-c391-3c235cf59c48"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","3/3 [==============================] - ETA: 0s - loss: 575.2350  ----------------------------------------------------------------------------------------------------\n","Word Error Rate: 1.0000\n","----------------------------------------------------------------------------------------------------\n","Target    : የ ረ ሙስና ኮሚሽን ክስ የ መሰረተ ባቸው እነዚሁ ግለሰቦች ማክሰኞ እ ለት ከፍተኛው ፍርድ ቤት እንደሚ ቀርቡ ም ለማወቅ ተችሏል\n","Prediction: \n","----------------------------------------------------------------------------------------------------\n","Target    : በመሆኑ ም ተጠያቂ ው ሂሳብ ሹም ሆነው እንደ ገና ገንዘብ በ ስማቸው ወጪ እንዲሆን ያደረጉት መሪጌታ ፍቅረ ማርያም ዋጋው ሆነው እንደ ተገኙ ተጠቅ ሷል\n","Prediction: \n","----------------------------------------------------------------------------------------------------\n","3/3 [==============================] - 1022s 323s/step - loss: 575.2350 - val_loss: 1602.2678\n","Epoch 2/5\n","3/3 [==============================] - ETA: 0s - loss: 506.7318  ----------------------------------------------------------------------------------------------------\n","Word Error Rate: 1.0000\n","----------------------------------------------------------------------------------------------------\n","Target    : አባታችሁ እየተዋጋ ን እናንተ በ መንግስታችን በ ሰላም ልት ኖሩ አትችሉ ም በ ማለት የ ታሰሩት የ እነዚህ ህናት እናት ልጆቿ ን እንዳ ታያቸው ና ስንቅ እንዳት ሰጣቸው መከልከሏ እንዳሳዘነ ው ገልጧል\n","Prediction: \n","----------------------------------------------------------------------------------------------------\n","Target    : በተለይ ካህናቱ ለውጡ ን ያስገኘ ላቸውን ኮሚሽን ሺ አመት ይንገ ሱ በ ማለት ምስጋና ና ምርቃት እየ ለገሱ ለት ነው\n","Prediction: \n","----------------------------------------------------------------------------------------------------\n","3/3 [==============================] - 1000s 318s/step - loss: 506.7318 - val_loss: 682.1271\n","Epoch 3/5\n","3/3 [==============================] - ETA: 0s - loss: 378.2223  ----------------------------------------------------------------------------------------------------\n","Word Error Rate: 1.0000\n","----------------------------------------------------------------------------------------------------\n","Target    : ፓርላማው በጀት ሳ ያድቅ ሊ በተን ነው\n","Prediction: \n","----------------------------------------------------------------------------------------------------\n","Target    : አባታችሁ እየተዋጋ ን እናንተ በ መንግስታችን በ ሰላም ልት ኖሩ አትችሉ ም በ ማለት የ ታሰሩት የ እነዚህ ህናት እናት ልጆቿ ን እንዳ ታያቸው ና ስንቅ እንዳት ሰጣቸው መከልከሏ እንዳሳዘነ ው ገልጧል\n","Prediction: \n","----------------------------------------------------------------------------------------------------\n","3/3 [==============================] - 1031s 341s/step - loss: 378.2223 - val_loss: 659.0065\n","Epoch 4/5\n","3/3 [==============================] - ETA: 0s - loss: 346.2065  ----------------------------------------------------------------------------------------------------\n","Word Error Rate: 1.0000\n","----------------------------------------------------------------------------------------------------\n","Target    : አባታችሁ እየተዋጋ ን እናንተ በ መንግስታችን በ ሰላም ልት ኖሩ አትችሉ ም በ ማለት የ ታሰሩት የ እነዚህ ህናት እናት ልጆቿ ን እንዳ ታያቸው ና ስንቅ እንዳት ሰጣቸው መከልከሏ እንዳሳዘነ ው ገልጧል\n","Prediction: \n","----------------------------------------------------------------------------------------------------\n","Target    : አባታችሁ እየተዋጋ ን እናንተ በ መንግስታችን በ ሰላም ልት ኖሩ አትችሉ ም በ ማለት የ ታሰሩት የ እነዚህ ህናት እናት ልጆቿ ን እንዳ ታያቸው ና ስንቅ እንዳት ሰጣቸው መከልከሏ እንዳሳዘነ ው ገልጧል\n","Prediction: \n","----------------------------------------------------------------------------------------------------\n","3/3 [==============================] - 1044s 344s/step - loss: 346.2065 - val_loss: 441.9717\n","Epoch 5/5\n","3/3 [==============================] - ETA: 0s - loss: 294.9075  ----------------------------------------------------------------------------------------------------\n","Word Error Rate: 1.0000\n","----------------------------------------------------------------------------------------------------\n","Target    : ጠጁ ን  መ መ  መ መ ና ሚስቱ ን ሲ ያሰቃ ያት አደረ\n","Prediction: \n","----------------------------------------------------------------------------------------------------\n","Target    : ጠጁ ን  መ መ  መ መ ና ሚስቱ ን ሲ ያሰቃ ያት አደረ\n","Prediction: \n","----------------------------------------------------------------------------------------------------\n","3/3 [==============================] - 1045s 335s/step - loss: 294.9075 - val_loss: 393.5096\n"]}]}]}