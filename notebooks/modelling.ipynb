{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"modelling.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPKe/k3TmbbX6+7WoKtUYje"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-VsREPJdlJCw","executionInfo":{"status":"ok","timestamp":1654417577499,"user_tz":-180,"elapsed":9530,"user":{"displayName":"Selam Ayehubirhan","userId":"06798422864346636867"}},"outputId":"198edd99-72e3-4783-8b7a-60d149c9ac5b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: jiwer in /usr/local/lib/python3.7/dist-packages (2.3.0)\n","Requirement already satisfied: python-Levenshtein==0.12.2 in /usr/local/lib/python3.7/dist-packages (from jiwer) (0.12.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from python-Levenshtein==0.12.2->jiwer) (57.4.0)\n"]}],"source":["!pip install jiwer\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","import matplotlib.pyplot as plt\n","from IPython import display\n","from jiwer import wer\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import FunctionTransformer"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JONPcY77lSCT","executionInfo":{"status":"ok","timestamp":1654417579744,"user_tz":-180,"elapsed":2258,"user":{"displayName":"Selam Ayehubirhan","userId":"06798422864346636867"}},"outputId":"ddbeb35f-f858-46af-f3eb-3bcda02b8a32"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import os\n","os.chdir(\"drive/MyDrive/AMHARIC\")\n","os.listdir()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"72zyhw88lTWg","executionInfo":{"status":"ok","timestamp":1654417579746,"user_tz":-180,"elapsed":25,"user":{"displayName":"Selam Ayehubirhan","userId":"06798422864346636867"}},"outputId":"572e4a0e-1a9d-4e36-9e18-e3182586c2ff"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['README.md',\n"," 'data',\n"," 'kaldi-script',\n"," 'lang',\n"," 'lm',\n"," 'metadata.csv',\n"," 'realmeta.csv']"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["meta_data = pd.read_csv(\"realmeta.csv\")\n","meta_data. drop(\"Unnamed: 0\", axis=1, inplace=True)\n","meta_data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"1MAF05gplUBw","executionInfo":{"status":"ok","timestamp":1654417580151,"user_tz":-180,"elapsed":417,"user":{"displayName":"Selam Ayehubirhan","userId":"06798422864346636867"}},"outputId":"8e001992-b70d-4157-b5bb-dabc222c1d65"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                      audio                                         Transcript\n","0          tr_1_tr01001.wav                    ያንደኛ ደረጃ ትምህርታቸው ን ጐንደር ተ ም ረዋል\n","1          tr_2_tr01002.wav  የተ ለቀቁት ምርኮኞች በ አካባቢያቸው ሰላማዊ ኑሮ እንዲ ኖሩ የ ትራንስፖ...\n","2          tr_3_tr01003.wav  በ አዲስ አበባው ስታዲየም በ ተካሄዱ ት ሁለት ግጥሚያ ዎች በ መጀመሪያ ...\n","3          tr_4_tr01004.wav                          ወሬው ን ወሬ ያደረጉ ምስጢረ ኞች ናቸው\n","4          tr_5_tr01005.wav   ኢትዮጵያዊ ቷ በ ብሄራዊ ባህላዊ አለባበስ ከ አለም አንደኝነት ን ተቀዳጀ ች\n","...                     ...                                                ...\n","10870  tr_10871_tr09145.wav                                      እንስራ ው ተ ሸነቆረ\n","10871  tr_10872_tr09146.wav                     ቤዛ ጐረ መሰ መሰለኝ ትእዛዝ አል ቀበል ም አለ\n","10872  tr_10873_tr09147.wav                            በለጠ ች የ በየነ የ በኩር ልጅ ነች\n","10873  tr_10874_tr09148.wav      እንዲያ መሬት አይ ን ካ ኝ ይል የነበረ ሰው በ ድንገት ቆረቆዘ አይደል\n","10874  tr_10875_tr09149.wav                           እጀ ጐልዳ ፋው ሰው ዬ መጻፍ አይችልም\n","\n","[10875 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-f06d625f-c181-40e4-b071-3454488a6e45\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>audio</th>\n","      <th>Transcript</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>tr_1_tr01001.wav</td>\n","      <td>ያንደኛ ደረጃ ትምህርታቸው ን ጐንደር ተ ም ረዋል</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>tr_2_tr01002.wav</td>\n","      <td>የተ ለቀቁት ምርኮኞች በ አካባቢያቸው ሰላማዊ ኑሮ እንዲ ኖሩ የ ትራንስፖ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>tr_3_tr01003.wav</td>\n","      <td>በ አዲስ አበባው ስታዲየም በ ተካሄዱ ት ሁለት ግጥሚያ ዎች በ መጀመሪያ ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>tr_4_tr01004.wav</td>\n","      <td>ወሬው ን ወሬ ያደረጉ ምስጢረ ኞች ናቸው</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>tr_5_tr01005.wav</td>\n","      <td>ኢትዮጵያዊ ቷ በ ብሄራዊ ባህላዊ አለባበስ ከ አለም አንደኝነት ን ተቀዳጀ ች</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>10870</th>\n","      <td>tr_10871_tr09145.wav</td>\n","      <td>እንስራ ው ተ ሸነቆረ</td>\n","    </tr>\n","    <tr>\n","      <th>10871</th>\n","      <td>tr_10872_tr09146.wav</td>\n","      <td>ቤዛ ጐረ መሰ መሰለኝ ትእዛዝ አል ቀበል ም አለ</td>\n","    </tr>\n","    <tr>\n","      <th>10872</th>\n","      <td>tr_10873_tr09147.wav</td>\n","      <td>በለጠ ች የ በየነ የ በኩር ልጅ ነች</td>\n","    </tr>\n","    <tr>\n","      <th>10873</th>\n","      <td>tr_10874_tr09148.wav</td>\n","      <td>እንዲያ መሬት አይ ን ካ ኝ ይል የነበረ ሰው በ ድንገት ቆረቆዘ አይደል</td>\n","    </tr>\n","    <tr>\n","      <th>10874</th>\n","      <td>tr_10875_tr09149.wav</td>\n","      <td>እጀ ጐልዳ ፋው ሰው ዬ መጻፍ አይችልም</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>10875 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f06d625f-c181-40e4-b071-3454488a6e45')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f06d625f-c181-40e4-b071-3454488a6e45 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f06d625f-c181-40e4-b071-3454488a6e45');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["split = int(len(meta_data) * 0.90)\n","df_train = meta_data[:split]\n","df_val = meta_data[split:]\n","\n","print(f\"Size of the training set: {len(df_train)}\")\n","print(f\"Size of the training set: {len(df_val)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LrIUXFbClUeo","executionInfo":{"status":"ok","timestamp":1654417580152,"user_tz":-180,"elapsed":15,"user":{"displayName":"Selam Ayehubirhan","userId":"06798422864346636867"}},"outputId":"bb9a61c0-f981-4b2e-c46e-463daa271920"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Size of the training set: 9787\n","Size of the training set: 1088\n"]}]},{"cell_type":"code","source":["supported = \"\"\"\n","ሀ ሁ ሂ ሄ ህ ሆ\n","ለ ሉ ሊ ላ ሌ ል ሎ ሏ\n","መ ሙ ሚ ማ ሜ ም ሞ ሟ\n","ረ ሩ ሪ ራ ሬ ር ሮ ሯ\n","ሰ ሱ ሲ ሳ ሴ ስ ሶ ሷ\n","ሸ ሹ ሺ ሻ ሼ ሽ ሾ ሿ\n","ቀ ቁ ቂ ቃ ቄ ቅ ቆ ቋ\n","በ ቡ ቢ ባ ቤ ብ ቦ ቧ\n","ቨ ቩ ቪ ቫ ቬ ቭ ቮ ቯ\n","ተ ቱ ቲ ታ ቴ ት ቶ ቷ\n","ቸ ቹ ቺ ቻ ቼ ች ቾ ቿ\n","ኋ\n","ነ ኑ ኒ ና ኔ ን ኖ ኗ\n","ኘ ኙ ኚ ኛ ኜ ኝ ኞ ኟ\n","አ ኡ ኢ ኤ እ ኦ\n","ኧ\n","ከ ኩ ኪ ካ ኬ ክ ኮ\n","ኳ\n","ወ ዉ ዊ ዋ ዌ ው ዎ\n","ዘ ዙ ዚ ዛ ዜ ዝ ዞ ዟ\n","ዠ ዡ ዢ ዣ ዤ ዥ ዦ ዧ\n","የ ዩ ዪ ያ ዬ ይ ዮ\n","ደ ዱ ዲ ዳ ዴ ድ ዶ ዷ\n","ጀ ጁ ጂ ጃ ጄ ጅ ጆ ጇ\n","ገ ጉ ጊ ጋ ጌ ግ ጐ ጓ ጔ\n","ጠ ጡ ጢ ጣ ጤ ጥ ጦ ጧ\n","ጨ ጩ ጪ ጫ ጬ ጭ ጮ ጯ\n","ጰ ጱ ጲ ጳ ጴ ጵ ጶ ጷ\n","ፀ ፁ ፂ ፃ ፄ ፅ ፆ ፇ\n","ፈ ፉ ፊ ፋ ፌ ፍ ፎ ፏ\n","ፐ ፑ ፒ ፓ ፔ ፕ ፖ\n","\"\"\".split()\n","\n","char_map = {}\n","char_map[\"\"] = 0\n","char_map[\" \"] = 1\n","index = 2\n","for c in supported:\n","    char_map[c] = index\n","    index += 1\n","index_map = {v+1: k for k, v in char_map.items()}\n","lan_lis = list(index_map.values())\n","print(lan_lis)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aaSJKq1wqCNf","executionInfo":{"status":"ok","timestamp":1654417580153,"user_tz":-180,"elapsed":14,"user":{"displayName":"Selam Ayehubirhan","userId":"06798422864346636867"}},"outputId":"63728d2f-36b2-49c3-cbc7-3db694cd0da2"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["['', ' ', 'ሀ', 'ሁ', 'ሂ', 'ሄ', 'ህ', 'ሆ', 'ለ', 'ሉ', 'ሊ', 'ላ', 'ሌ', 'ል', 'ሎ', 'ሏ', 'መ', 'ሙ', 'ሚ', 'ማ', 'ሜ', 'ም', 'ሞ', 'ሟ', 'ረ', 'ሩ', 'ሪ', 'ራ', 'ሬ', 'ር', 'ሮ', 'ሯ', 'ሰ', 'ሱ', 'ሲ', 'ሳ', 'ሴ', 'ስ', 'ሶ', 'ሷ', 'ሸ', 'ሹ', 'ሺ', 'ሻ', 'ሼ', 'ሽ', 'ሾ', 'ሿ', 'ቀ', 'ቁ', 'ቂ', 'ቃ', 'ቄ', 'ቅ', 'ቆ', 'ቋ', 'በ', 'ቡ', 'ቢ', 'ባ', 'ቤ', 'ብ', 'ቦ', 'ቧ', 'ቨ', 'ቩ', 'ቪ', 'ቫ', 'ቬ', 'ቭ', 'ቮ', 'ቯ', 'ተ', 'ቱ', 'ቲ', 'ታ', 'ቴ', 'ት', 'ቶ', 'ቷ', 'ቸ', 'ቹ', 'ቺ', 'ቻ', 'ቼ', 'ች', 'ቾ', 'ቿ', 'ኋ', 'ነ', 'ኑ', 'ኒ', 'ና', 'ኔ', 'ን', 'ኖ', 'ኗ', 'ኘ', 'ኙ', 'ኚ', 'ኛ', 'ኜ', 'ኝ', 'ኞ', 'ኟ', 'አ', 'ኡ', 'ኢ', 'ኤ', 'እ', 'ኦ', 'ኧ', 'ከ', 'ኩ', 'ኪ', 'ካ', 'ኬ', 'ክ', 'ኮ', 'ኳ', 'ወ', 'ዉ', 'ዊ', 'ዋ', 'ዌ', 'ው', 'ዎ', 'ዘ', 'ዙ', 'ዚ', 'ዛ', 'ዜ', 'ዝ', 'ዞ', 'ዟ', 'ዠ', 'ዡ', 'ዢ', 'ዣ', 'ዤ', 'ዥ', 'ዦ', 'ዧ', 'የ', 'ዩ', 'ዪ', 'ያ', 'ዬ', 'ይ', 'ዮ', 'ደ', 'ዱ', 'ዲ', 'ዳ', 'ዴ', 'ድ', 'ዶ', 'ዷ', 'ጀ', 'ጁ', 'ጂ', 'ጃ', 'ጄ', 'ጅ', 'ጆ', 'ጇ', 'ገ', 'ጉ', 'ጊ', 'ጋ', 'ጌ', 'ግ', 'ጐ', 'ጓ', 'ጔ', 'ጠ', 'ጡ', 'ጢ', 'ጣ', 'ጤ', 'ጥ', 'ጦ', 'ጧ', 'ጨ', 'ጩ', 'ጪ', 'ጫ', 'ጬ', 'ጭ', 'ጮ', 'ጯ', 'ጰ', 'ጱ', 'ጲ', 'ጳ', 'ጴ', 'ጵ', 'ጶ', 'ጷ', 'ፀ', 'ፁ', 'ፂ', 'ፃ', 'ፄ', 'ፅ', 'ፆ', 'ፇ', 'ፈ', 'ፉ', 'ፊ', 'ፋ', 'ፌ', 'ፍ', 'ፎ', 'ፏ', 'ፐ', 'ፑ', 'ፒ', 'ፓ', 'ፔ', 'ፕ', 'ፖ']\n"]}]},{"cell_type":"code","source":["wavs_path_train = (\"data/train/wav/\")\n","wavs_path_test = (\"data/test/wav/\")"],"metadata":{"id":"qlESw6l8rjLW","executionInfo":{"status":"ok","timestamp":1654417580154,"user_tz":-180,"elapsed":13,"user":{"displayName":"Selam Ayehubirhan","userId":"06798422864346636867"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Mapping characters to integers\n","char_to_num = keras.layers.StringLookup(vocabulary=lan_lis, oov_token=\"\")\n","# Mapping integers back to original characters\n","num_to_char = keras.layers.StringLookup(\n","    vocabulary=char_to_num.get_vocabulary(), oov_token=\"\", invert=True\n",")"],"metadata":{"id":"ogzcIuDtlUub","executionInfo":{"status":"ok","timestamp":1654417580155,"user_tz":-180,"elapsed":14,"user":{"displayName":"Selam Ayehubirhan","userId":"06798422864346636867"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# An integer scalar Tensor. The window length in samples.\n","frame_length = 256\n","# An integer scalar Tensor. The number of samples to step.\n","frame_step = 160\n","# An integer scalar Tensor. The size of the FFT to apply.\n","# If not provided, uses the smallest power of 2 enclosing frame_length.\n","fft_length = 384\n","\n","\n","def encode_single_sample(wav_file, label):\n","    ###########################################\n","    ##  Process the Audio\n","    ##########################################\n","    # 1. Read wav file\n","    file = tf.io.read_file(wavs_path_train + wav_file)\n","    # 2. Decode the wav file\n","    audio, _ = tf.audio.decode_wav(file)\n","    audio = tf.squeeze(audio, axis=-1)\n","    # 3. Change type to float\n","    audio = tf.cast(audio, tf.float32)\n","    # 4. Get the spectrogram\n","    spectrogram = tf.signal.stft(\n","        audio, frame_length=frame_length, frame_step=frame_step, fft_length=fft_length\n","    )\n","    # 5. We only need the magnitude, which can be derived by applying tf.abs\n","    spectrogram = tf.abs(spectrogram)\n","    spectrogram = tf.math.pow(spectrogram, 0.5)\n","    # 6. normalisation\n","    means = tf.math.reduce_mean(spectrogram, 1, keepdims=True)\n","    stddevs = tf.math.reduce_std(spectrogram, 1, keepdims=True)\n","    spectrogram = (spectrogram - means) / (stddevs + 1e-10)\n","    ###########################################\n","    ##  Process the label\n","    ##########################################\n","    # 7. Convert label to Lower case\n","    label = tf.strings.lower(label)\n","    # 8. Split the label\n","    label = tf.strings.unicode_split(label, input_encoding=\"UTF-8\")\n","    # 9. Map the characters in label to numbers\n","    label = char_to_num(label)\n","    # 10. Return a dict as our model is expecting two inputs\n","    return spectrogram, label"],"metadata":{"id":"Nih9uRsnlVZw","executionInfo":{"status":"ok","timestamp":1654417580156,"user_tz":-180,"elapsed":14,"user":{"displayName":"Selam Ayehubirhan","userId":"06798422864346636867"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["batch_size = 32\n","# Define the trainig dataset\n","train_dataset = tf.data.Dataset.from_tensor_slices(\n","    (list(df_train[\"audio\"]), list(df_train[\"Transcript\"]))\n",")\n","train_dataset = (\n","    train_dataset.map(encode_single_sample, num_parallel_calls=tf.data.AUTOTUNE)\n","    .padded_batch(batch_size)\n","    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",")\n","\n","# Define the validation dataset\n","validation_dataset = tf.data.Dataset.from_tensor_slices(\n","    (list(df_val[\"audio\"]), list(df_val[\"Transcript\"]))\n",")\n","validation_dataset = (\n","    validation_dataset.map(encode_single_sample, num_parallel_calls=tf.data.AUTOTUNE)\n","    .padded_batch(batch_size)\n","    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",")"],"metadata":{"id":"SDudniwkqnmY","executionInfo":{"status":"ok","timestamp":1654417580963,"user_tz":-180,"elapsed":820,"user":{"displayName":"Selam Ayehubirhan","userId":"06798422864346636867"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def CTCLoss(y_true, y_pred):\n","    # Compute the training-time loss value\n","    batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n","    input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n","    label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n","\n","    input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n","    label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n","\n","    loss = keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n","    return loss"],"metadata":{"id":"1jPV4KQ2qpeG","executionInfo":{"status":"ok","timestamp":1654417580966,"user_tz":-180,"elapsed":8,"user":{"displayName":"Selam Ayehubirhan","userId":"06798422864346636867"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["def build_model(input_dim, output_dim, rnn_layers=5, rnn_units=128):\n","    \"\"\"Model similar to DeepSpeech2.\"\"\"\n","    # Model's input\n","    input_spectrogram = layers.Input((None, input_dim), name=\"input\")\n","    # Expand the dimension to use 2D CNN.\n","    x = layers.Reshape((-1, input_dim, 1), name=\"expand_dim\")(input_spectrogram)\n","    # Convolution layer 1\n","    x = layers.Conv2D(\n","        filters=32,\n","        kernel_size=[11, 41],\n","        strides=[2, 2],\n","        padding=\"same\",\n","        use_bias=False,\n","        name=\"conv_1\",\n","    )(x)\n","    x = layers.BatchNormalization(name=\"conv_1_bn\")(x)\n","    x = layers.ReLU(name=\"conv_1_relu\")(x)\n","    # Convolution layer 2\n","    x = layers.Conv2D(\n","        filters=32,\n","        kernel_size=[11, 21],\n","        strides=[1, 2],\n","        padding=\"same\",\n","        use_bias=False,\n","        name=\"conv_2\",\n","    )(x)\n","    x = layers.BatchNormalization(name=\"conv_2_bn\")(x)\n","    x = layers.ReLU(name=\"conv_2_relu\")(x)\n","    # Reshape the resulted volume to feed the RNNs layers\n","    x = layers.Reshape((-1, x.shape[-2] * x.shape[-1]))(x)\n","    # RNN layers\n","    for i in range(1, rnn_layers + 1):\n","        recurrent = layers.GRU(\n","            units=rnn_units,\n","            activation=\"tanh\",\n","            recurrent_activation=\"sigmoid\",\n","            use_bias=True,\n","            return_sequences=True,\n","            reset_after=True,\n","            name=f\"gru_{i}\",\n","        )\n","        x = layers.Bidirectional(\n","            recurrent, name=f\"bidirectional_{i}\", merge_mode=\"concat\"\n","        )(x)\n","        if i < rnn_layers:\n","            x = layers.Dropout(rate=0.5)(x)\n","    # Dense layer\n","    x = layers.Dense(units=rnn_units * 2, name=\"dense_1\")(x)\n","    x = layers.ReLU(name=\"dense_1_relu\")(x)\n","    x = layers.Dropout(rate=0.5)(x)\n","    # Classification layer\n","    output = layers.Dense(units=output_dim + 1, activation=\"softmax\")(x)\n","    # Model\n","    model = keras.Model(input_spectrogram, output, name=\"DeepSpeech_2\")\n","    # Optimizer\n","    opt = keras.optimizers.Adam(learning_rate=1e-4)\n","    # Compile the model and return\n","    model.compile(optimizer=opt, loss=CTCLoss)\n","    return model\n","\n","\n","# Get the model\n","model = build_model(\n","    input_dim=fft_length // 2 + 1,\n","    output_dim=char_to_num.vocabulary_size(),\n","    rnn_units=512,\n",")\n","model.summary(line_length=110)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lNh8FdmEqp5l","executionInfo":{"status":"ok","timestamp":1654417585951,"user_tz":-180,"elapsed":4992,"user":{"displayName":"Selam Ayehubirhan","userId":"06798422864346636867"}},"outputId":"7fa9be57-ff71-4947-ea29-7fb83d573e0b"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"DeepSpeech_2\"\n","______________________________________________________________________________________________________________\n"," Layer (type)                                    Output Shape                                Param #          \n","==============================================================================================================\n"," input (InputLayer)                              [(None, None, 193)]                         0                \n","                                                                                                              \n"," expand_dim (Reshape)                            (None, None, 193, 1)                        0                \n","                                                                                                              \n"," conv_1 (Conv2D)                                 (None, None, 97, 32)                        14432            \n","                                                                                                              \n"," conv_1_bn (BatchNormalization)                  (None, None, 97, 32)                        128              \n","                                                                                                              \n"," conv_1_relu (ReLU)                              (None, None, 97, 32)                        0                \n","                                                                                                              \n"," conv_2 (Conv2D)                                 (None, None, 49, 32)                        236544           \n","                                                                                                              \n"," conv_2_bn (BatchNormalization)                  (None, None, 49, 32)                        128              \n","                                                                                                              \n"," conv_2_relu (ReLU)                              (None, None, 49, 32)                        0                \n","                                                                                                              \n"," reshape (Reshape)                               (None, None, 1568)                          0                \n","                                                                                                              \n"," bidirectional_1 (Bidirectional)                 (None, None, 1024)                          6395904          \n","                                                                                                              \n"," dropout (Dropout)                               (None, None, 1024)                          0                \n","                                                                                                              \n"," bidirectional_2 (Bidirectional)                 (None, None, 1024)                          4724736          \n","                                                                                                              \n"," dropout_1 (Dropout)                             (None, None, 1024)                          0                \n","                                                                                                              \n"," bidirectional_3 (Bidirectional)                 (None, None, 1024)                          4724736          \n","                                                                                                              \n"," dropout_2 (Dropout)                             (None, None, 1024)                          0                \n","                                                                                                              \n"," bidirectional_4 (Bidirectional)                 (None, None, 1024)                          4724736          \n","                                                                                                              \n"," dropout_3 (Dropout)                             (None, None, 1024)                          0                \n","                                                                                                              \n"," bidirectional_5 (Bidirectional)                 (None, None, 1024)                          4724736          \n","                                                                                                              \n"," dense_1 (Dense)                                 (None, None, 1024)                          1049600          \n","                                                                                                              \n"," dense_1_relu (ReLU)                             (None, None, 1024)                          0                \n","                                                                                                              \n"," dropout_4 (Dropout)                             (None, None, 1024)                          0                \n","                                                                                                              \n"," dense (Dense)                                   (None, None, 223)                           228575           \n","                                                                                                              \n","==============================================================================================================\n","Total params: 26,824,255\n","Trainable params: 26,824,127\n","Non-trainable params: 128\n","______________________________________________________________________________________________________________\n"]}]},{"cell_type":"code","source":["# A utility function to decode the output of the network\n","def decode_batch_predictions(pred):\n","    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n","    # Use greedy search. For complex tasks, you can use beam search\n","    results = keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0]\n","    # Iterate over the results and get back the text\n","    output_text = []\n","    for result in results:\n","        result = tf.strings.reduce_join(num_to_char(result)).numpy().decode(\"utf-8\")\n","        output_text.append(result)\n","    return output_text\n","\n","\n","# A callback class to output a few transcriptions during training\n","class CallbackEval(keras.callbacks.Callback):\n","    \"\"\"Displays a batch of outputs after every epoch.\"\"\"\n","\n","    def __init__(self, dataset):\n","        super().__init__()\n","        self.dataset = dataset\n","\n","    def on_epoch_end(self, epoch: int, logs=None):\n","        predictions = []\n","        targets = []\n","        for batch in self.dataset:\n","            X, y = batch\n","            batch_predictions = model.predict(X)\n","            batch_predictions = decode_batch_predictions(batch_predictions)\n","            predictions.extend(batch_predictions)\n","            for label in y:\n","                label = (\n","                    tf.strings.reduce_join(num_to_char(label)).numpy().decode(\"utf-8\")\n","                )\n","                targets.append(label)\n","        wer_score = wer(targets, predictions)\n","        print(\"-\" * 100)\n","        print(f\"Word Error Rate: {wer_score:.4f}\")\n","        print(\"-\" * 100)\n","        for i in np.random.randint(0, len(predictions), 2):\n","            print(f\"Target    : {targets[i]}\")\n","            print(f\"Prediction: {predictions[i]}\")\n","            print(\"-\" * 100)"],"metadata":{"id":"ioDNjjG2qqet","executionInfo":{"status":"ok","timestamp":1654417586461,"user_tz":-180,"elapsed":514,"user":{"displayName":"Selam Ayehubirhan","userId":"06798422864346636867"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# Define the number of epochs.\n","epochs = 1\n","# Callback function to check transcription on the val set.\n","validation_callback = CallbackEval(validation_dataset)\n","# Train the model\n","history = model.fit(\n","    train_dataset,\n","    validation_data=validation_dataset,\n","    epochs=epochs,\n","    callbacks=[validation_callback],\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SMQ4BhYSlV_Q","outputId":"d418168e-4950-4233-ab9c-b89554d5b318"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" 17/306 [>.............................] - ETA: 23:43:25 - loss: 1037.6315"]}]}]}