{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install python_speech_features\n",
    "!pip install librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa   #for audio processing\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.io import wavfile #for audio processing\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading Audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tran_loader(filename):\n",
    "    name_to_text = {}\n",
    "    with open (filename, encoding=\"utf-8\")as f:\n",
    "        f.readline()\n",
    "        for line in f:\n",
    "            name=line.split(\"</s>\")[1]\n",
    "            name=name.replace('(', '')\n",
    "            name=name.replace(')', '')\n",
    "            name=name.replace('\\n','')\n",
    "            name=name.replace(' ','')\n",
    "            text=line.split(\"</s>\")[0]\n",
    "            text=text.replace(\"<s>\",\"\")\n",
    "            name_to_text[name]=text\n",
    "        return name_to_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription=tran_loader(r\"C:\\Users\\sam\\Desktop\\lang\\AMHARIC\\data\\trsTrain.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meta_data(trans, path ):\n",
    "    target=[]\n",
    "    features=[]\n",
    "    filenames=[]\n",
    "    duration_of_recordings=[]\n",
    "    for k in trans:\n",
    "        filename=path+k +\".wav\"\n",
    "        filenames.append(filename)\n",
    "        audio, fs = librosa.load(filename, sr=None)\n",
    "        duration_of_recordings.append(float(len(audio)/fs))\n",
    "\n",
    "        lable = trans[k]\n",
    "        target.append(lable)\n",
    "    return filenames, target,duration_of_recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames, target,duration_of_recordings= meta_data(transcription,'valid/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "data=pd.DataFrame({'key': filenames,'text': target, 'duration':duration_of_recordings})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import torchaudio\n",
    "\n",
    "class Audio_load():\n",
    "    # ----------------------------\n",
    "    # Load an audio file. Return the signal as a tensor and the sample rate\n",
    "    # ----------------------------\n",
    "    def open(audio_file):\n",
    "        sig, sr = librosa.load(audio_file, sr=44100)\n",
    "        return (sig, sr)\n",
    "    \n",
    "    \n",
    "    def rechannel(aud, new_channel):\n",
    "        sig, sr = aud\n",
    "\n",
    "        if (sig.shape[0] == new_channel):\n",
    "            # Nothing to do\n",
    "            return aud\n",
    "\n",
    "        if (new_channel == 1):\n",
    "            # Convert from stereo to mono by selecting only the first channel\n",
    "            resig = audio[:1, :]\n",
    "        else:\n",
    "            # Convert from mono to stereo by duplicating the first channel\n",
    "#             resig = torch.cat([audio, sudio])\n",
    "\n",
    "        return ((resig, sr))\n",
    "\n",
    "    def resample(aud, newsr):\n",
    "        sig, sr = aud\n",
    "\n",
    "        if (sr == newsr):\n",
    "            # Nothing to do\n",
    "            return aud\n",
    "\n",
    "        num_channels = sig.shape[0]\n",
    "        # Resample first channel\n",
    "        reaudio = torchaudio.transforms.Resample(sr, new_rate)(sig[:1,:])\n",
    "        if (num_channels > 1):\n",
    "            # Resample the second channel and merge both channels\n",
    "            retwo = torchaudio.transforms.Resample(sr, new_rate)(sig[1:,:])\n",
    "            resig = torch.cat([resig, retwo])\n",
    "\n",
    "        return ((resig, new_rate))\n",
    "\n",
    "    def pad_trunc(aud, max_ms):\n",
    "        sig, sr = aud\n",
    "        num_rows, sig_len = sig.shape\n",
    "        max_len = sr//1000 * max_ms\n",
    "\n",
    "        if (sig_len > max_len):\n",
    "            # Truncate the signal to the given length\n",
    "            sig= sig[:,:max_len]\n",
    "\n",
    "        elif (sig_len < max_len):\n",
    "            # Length of padding to add at the beginning and end of the signal\n",
    "            pad_begin_len = random.randint(0, max_len - sig_len)\n",
    "            pad_end_len = max_len - sig_len - pad_begin_len\n",
    "\n",
    "            # Pad with 0s\n",
    "            pad_begin = torch.zeros((num_rows, pad_begin_len))\n",
    "            pad_end = torch.zeros((num_rows, pad_end_len))\n",
    "\n",
    "            sig = torch.cat((pad_begin, sig, pad_end), 1)\n",
    "      \n",
    "        return (sig, sr)\n",
    "\n",
    "    def time_shift(aud, shift_limit):\n",
    "        sig,sr = aud\n",
    "        _, sig_len = sig.shape\n",
    "        shift_amt = int(random.random() * shift_limit * sig_len)\n",
    "        return (sig.roll(shift_amt), sr)\n",
    "    \n",
    "    def spectro_gram(aud, n_mels=64, n_fft=1024, hop_len=None):\n",
    "        sig,sr = aud\n",
    "        top_db = 80\n",
    "\n",
    "        # spec has shape [channel, n_mels, time], where channel is mono, stereo etc\n",
    "        spec = transforms.MelSpectrogram(sr, n_fft=n_fft, hop_length=hop_len, n_mels=n_mels)(sig)\n",
    "\n",
    "        # Convert to decibels\n",
    "        spec = transforms.AmplitudeToDB(top_db=top_db)(spec)\n",
    "        return (spec)\n",
    "    \n",
    "    def spectro_augment(spec, max_mask_pct=0.1, n_freq_masks=1, n_time_masks=1):\n",
    "        _, n_mels, n_steps = spec.shape\n",
    "        mask_value = spec.mean()\n",
    "        aug_spec = spec\n",
    "\n",
    "        freq_mask_param = max_mask_pct * n_mels\n",
    "        for _ in range(n_freq_masks):\n",
    "            aug_spec = transforms.FrequencyMasking(freq_mask_param)(aug_spec, mask_value)\n",
    "\n",
    "        time_mask_param = max_mask_pct * n_steps\n",
    "        for _ in range(n_time_masks):\n",
    "            aug_spec = transforms.TimeMasking(time_mask_param)(aug_spec, mask_value)\n",
    "\n",
    "        return aug_spec\n",
    "    \n",
    "    def show_wave(aud, label='', ax=None):\n",
    "        sig, sr = aud\n",
    "        if (not ax):\n",
    "            _,ax = plt.subplots(1, 1, figsize=(3, 3))\n",
    "    \n",
    "        ax.plot(sig[0])\n",
    "        ax.set_title(label)\n",
    "    \n",
    "    def show_transform(orig, trans):\n",
    "        osig,osr = orig\n",
    "        tsig,tsr = trans\n",
    "        if orig is not None: plt.plot(osig[0], 'm', label=\"Orig.\")\n",
    "        if trans is not None: plt.plot(tsig[0], 'c', alpha=0.5, label=\"Transf.\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    def show_spectro(spec, label='', ax=None, figsize=(6,6)):\n",
    "        if (not ax):\n",
    "            _,ax = plt.subplots(1, 1, figsize=figsize)\n",
    "        # Reduce first dimension if it is greyscale\n",
    "        ax.imshow(spec if (spec.shape[0]==3) else spec.squeeze(0))\n",
    "        ax.set_title(f'{label}, {list(spec.shape)}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import torchaudio\n",
    "\n",
    "# ----------------------------\n",
    "# Sound Dataset\n",
    "# ----------------------------\n",
    "class SoundDS(Dataset):\n",
    "    def __init__(self, df, data_path):\n",
    "        self.df = df\n",
    "        self.data_path = str(data_path)\n",
    "        self.duration = 4000\n",
    "        self.sr = 44100\n",
    "        self.channel = 2\n",
    "        self.shift_pct = 0.4\n",
    "\n",
    "    # ----------------------------\n",
    "    # Number of items in dataset\n",
    "    # ----------------------------\n",
    "    def __len__(self):\n",
    "        return len(self.df)    \n",
    "\n",
    "    # ----------------------------\n",
    "    # Get i'th item in dataset\n",
    "    # ----------------------------\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        # Absolute file path of the audio file - concatenate the audio directory with\n",
    "        # the relative path\n",
    "        audio_file = self.data_path + self.df.loc[idx, 'relative_path']\n",
    "        # Get the Class ID\n",
    "        class_id = self.df.loc[idx, 'classID']\n",
    "\n",
    "        aud = AudioUtil.open(audio_file)\n",
    "        # Some sounds have a higher sample rate, or fewer channels compared to the\n",
    "        # majority. So make all sounds have the same number of channels and same \n",
    "        # sample rate. Unless the sample rate is the same, the pad_trunc will still\n",
    "        # result in arrays of different lengths, even though the sound duration is\n",
    "        # the same.\n",
    "        reaud = AudioUtil.resample(aud, self.sr)\n",
    "        rechan = AudioUtil.rechannel(reaud, self.channel)\n",
    "\n",
    "        dur_aud = AudioUtil.pad_trunc(rechan, self.duration)\n",
    "        shift_aud = AudioUtil.time_shift(dur_aud, self.shift_pct)\n",
    "        sgram = AudioUtil.spectro_gram(shift_aud, n_mels=64, n_fft=1024, hop_len=None)\n",
    "        aug_sgram = AudioUtil.spectro_augment(sgram, max_mask_pct=0.1, n_freq_masks=2, n_time_masks=2)\n",
    "\n",
    "        return aug_sgram, class_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
